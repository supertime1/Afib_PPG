{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Afib_ECG_125Hz.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/Afib_PPG/blob/master/Afib_ECG_125Hz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oNUq1dRJq-r",
        "colab_type": "text"
      },
      "source": [
        "#1.Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIS5QlL3G0G7",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains an ECG DNN by using labeled ECG data from \"The PhysioNet Computing in Cardiology Challenge 2017\" (https://physionet.org/content/challenge-2017/1.0.0/). The ECG DNN model will be used to label the ECG data from MIMIC-III waveform dataset, so as the concurrent PPG data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSibYKc0KaNC",
        "colab_type": "text"
      },
      "source": [
        "The ECG data used in training and validation has the following important attributes:\n",
        "*   sampling frequency: 300Hz\n",
        "*   4 lables: Normal (N), AF (A), Other rhythm (O), Noisy (~)\n",
        "*   length: 9 - 60s with 30s mean.\n",
        "*   preprosessed: data has been band pass filtered by AliveCor device\n",
        "\n",
        "\n",
        "Only time length >30s is used in training, since PPG data usually requires 30s for Afib detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9YY9bo0CLNy",
        "colab_type": "text"
      },
      "source": [
        "#2.Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGo63wdRGY03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sklearn.metrics\n",
        "import sklearn\n",
        "import itertools\n",
        "import io\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsKVuNWV6t4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this cell if multiple GPUs are used\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xia3EgQ6-gNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuQ_w0-N-nrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyD6ZPEDKyYw",
        "colab_type": "text"
      },
      "source": [
        "#3.Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkIhig4MCdvc",
        "colab_type": "text"
      },
      "source": [
        "##3.1 Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C6pSdgSIGvl",
        "colab_type": "text"
      },
      "source": [
        "###3.1.1 Load training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Totv4fFHKwED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hd_names = []\n",
        "for name in glob.glob(\"C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib ECG data/training2017/*.hea\"):\n",
        "  position = name.index('.hea')\n",
        "  name = name[0:position] #remove the .hea part to comply with the wfdb.rdrecord format\n",
        "  hd_names.append(name)\n",
        "print('There are total', len(hd_names), 'records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50P04jUzLgZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qualified_names = [] #a list of file names that contain ECG Lead I data\n",
        "for name in hd_names:\n",
        "  record = wfdb.rdheader(name)\n",
        "  if record.sig_len >= 9000: #extact only records contrains ECG lead I >30s\n",
        "    qualified_names.append(name)\n",
        "print('There are total', len(qualified_names), 'qualified (>30s) records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39lu0EfVOxso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load label numpy file\n",
        "df = pd.read_csv(r'C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\Afib ECG data\\training2017\\REFERENCE.csv', sep=',', header=None) \n",
        "#create a new name list that only stores the file name\n",
        "init_labels =[]\n",
        "new_names = []\n",
        "for name in qualified_names:\n",
        "  temp_name = name[-6:] #remove the dir and keep only the file name\n",
        "  temp_label = df[df[0] == temp_name][1].to_numpy()\n",
        "  if temp_label != '~':\n",
        "    init_labels.append(temp_label)\n",
        "    new_names.append(name)\n",
        "init_labels = np.array(init_labels)\n",
        "\n",
        "init_labels[init_labels =='N'] = '0'\n",
        "init_labels[init_labels =='A'] = '1'\n",
        "init_labels[init_labels =='O'] = '0'\n",
        "\n",
        "print('There are total', len(init_labels),'none-nosiy labels')\n",
        "print('There are total', len(new_names), 'none-nosiy records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ribTthakZcx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##read signals\n",
        "ECG_signals = [] #create a  list to store all  ECG signals\n",
        "for name in new_names:\n",
        "  record = wfdb.rdrecord(name)\n",
        "  ECG_signals.append(record.p_signal)\n",
        "\n",
        "print('ECG signals len:', len(ECG_signals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koI2rxjvaCAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A function to split the raw signal data with 30s per segment and keep the label\n",
        "##source is the raw signal (e.g. ECG_signals) and seg_len = 30s * 300Hz = 9000\n",
        "def generate_segment_data(source,init_labels,seg_len):\n",
        "  n=0\n",
        "  signals =[]\n",
        "  labels = []\n",
        "  for signal in source:\n",
        "    for i in range(int(len(signal)/seg_len)):\n",
        "      seg = signal[seg_len*i:seg_len*(i+1)]\n",
        "      label = init_labels[n]\n",
        "      signals.append(seg)\n",
        "      labels.append(label)\n",
        "    n+=1\n",
        "#convert list into a numpy array and change its dim from (num of records, seg_len, 1) to (num of records, seg_len)\n",
        "  signals = np.asarray(list(map(lambda x: np.reshape(x,9000),signals)))\n",
        "  labels = np.asarray(list(map(lambda x: np.reshape(x,1),labels)))\n",
        "\n",
        "  return signals,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVL-5Pxdc7C5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use generate_segment_data() to generate segments with labels\n",
        "#After segmentation, more data than previous is generated, because some source data are 60s \n",
        "signals, labels = generate_segment_data(ECG_signals,init_labels,9000)\n",
        "print('signals dim:',signals.shape)\n",
        "print('labels dim:',labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGcS3odRKMjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add normalization to signals\n",
        "signals = sklearn.preprocessing.scale(signals)\n",
        "print('signals dim:',signals.shape)\n",
        "print('labels dim:',labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu3CAQc4gf26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resample the ECG signal\n",
        "from wfdb import processing\n",
        "resamp_ECG_signals = []\n",
        "for i in range(len(signals)):\n",
        "  resamp_ECG_signal, t = wfdb.processing.resample_sig(signals[i],300,125)\n",
        "  resamp_ECG_signals.append(resamp_ECG_signal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NKrp_UIgq1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Resampled ECG signal dim:', len(resamp_ECG_signals[0]))\n",
        "print('Resampled ECG signals len:', len(resamp_ECG_signals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkEa2upgtXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(resamp_ECG_signals[1][:180]*-1,label = \"125Hz\")\n",
        "plt.figure()\n",
        "plt.plot(signals[1][:432]*-1, label=\"300Hz\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS-9DhgTgd7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resize the dimension for use in CNN\n",
        "signals = np.expand_dims(resamp_ECG_signals,axis=1)\n",
        "signals = np.expand_dims(signals,axis=3)\n",
        "print('signals dim after resize:',signals.shape)\n",
        "print('labels dim after resize:',labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQdFnfwT36px",
        "colab_type": "text"
      },
      "source": [
        "###3.1.2 Create train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WPHNzkD-baa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###ratio value is between 0 and 1\n",
        "def slice_dataset(dataset,labels,train_ratio,seed = 10):   #make sure seed is set to a same number for repeatable results\n",
        "  DATASET_SIZE =len(list(dataset)) #only works in eager mode (e.g. TF version >= 2.0.x)\n",
        "  train_size = int(train_ratio * DATASET_SIZE)\n",
        "  val_size = DATASET_SIZE - train_size\n",
        "  \n",
        "  np.random.seed(seed=seed)\n",
        "  np.random.shuffle(dataset)\n",
        "  train_dataset = dataset[:train_size,:,:]\n",
        "  val_dataset = dataset[-val_size:,:,:]\n",
        "\n",
        "  np.random.seed(seed=seed)\n",
        "  np.random.shuffle(labels)\n",
        "  train_labels = labels[:train_size,:]\n",
        "  val_labels = labels[-val_size:,:]\n",
        "\n",
        "  return train_dataset,val_dataset,train_labels, val_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWDrV9ZeBKRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_signals, val_signals, train_labels, val_labels  = slice_dataset(signals,labels,0.9)\n",
        "print(\"train_dataset dim\", train_signals.shape)\n",
        "print(\"train_labels dim\", train_labels.shape)\n",
        "print(\"test_dataset dim\", val_signals.shape)\n",
        "print(\"test_labels dim\", val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYKjgw1A5TKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check unique labels in train dataset\n",
        "unique, count = np.unique(train_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in training dataset')\n",
        "print('There are', count[1], 'Afib records in training dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RFAlSls5WPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check unique labels in train dataset\n",
        "unique, count = np.unique(val_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in validation dataset')\n",
        "print('There are', count[1], 'Afib records in validation dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X0nuo2WIN5z",
        "colab_type": "text"
      },
      "source": [
        "###3.1.3 Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOKk0RBjFdYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load test data\n",
        "test_hd_names = []\n",
        "for name in glob.glob(\"C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib ECG data/validation/*.hea\"): \n",
        "  position = name.index('.hea')\n",
        "  name = name[0:position] #remove the .hea part to comply with the wfdb.rdrecord format\n",
        "  test_hd_names.append(name)\n",
        "print('There are total', len(test_hd_names), 'test records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4RhLECVIfEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_qualified_names = [] #a list of file names that contain ECG Lead I data\n",
        "for name in test_hd_names:\n",
        "  record = wfdb.rdheader(name)\n",
        "  if record.sig_len >= 9000: #extact only records contrains ECG lead I >30s\n",
        "    test_qualified_names.append(name)\n",
        "print('There are total', len(test_qualified_names), 'qualified (>30s) test records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJe47S6nkD5B",
        "colab": {}
      },
      "source": [
        "#load label numpy file\n",
        "df = pd.read_csv(r'C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\Afib ECG data\\validation\\REFERENCE.csv', sep=',', header=None) #'/content/drive/My Drive/training2017/REFERENCE.csv',sep=',', header=None)#\n",
        "#create a new name list that only stores the file name\n",
        "test_init_labels =[]\n",
        "test_new_names = []\n",
        "for name in test_qualified_names:\n",
        "  temp_name = name[-6:] #remove the dir and keep only the file name\n",
        "  temp_label = df[df[0] == temp_name][1].to_numpy()\n",
        "  if temp_label != '~':\n",
        "    test_init_labels.append(temp_label)\n",
        "    test_new_names.append(name)\n",
        "test_init_labels = np.array(test_init_labels)\n",
        "\n",
        "test_init_labels[test_init_labels =='N'] = '0'\n",
        "test_init_labels[test_init_labels =='A'] = '1'\n",
        "test_init_labels[test_init_labels =='O'] = '0'\n",
        "\n",
        "print('There are total', len(test_init_labels),'none-nosiy test labels')\n",
        "print('There are total', len(test_new_names), 'none-nosiy test records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ1dxW5DImG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##read signals\n",
        "test_ECG_signals = [] #create a  list to store all  ECG signals\n",
        "for name in test_new_names:\n",
        "  record = wfdb.rdrecord(name)\n",
        "  test_ECG_signals.append(record.p_signal)\n",
        "\n",
        "print('test ECG signals len:', len(test_ECG_signals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaxdW87UI1wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use generate_segment_data() to generate segments with labels\n",
        "#After segmentation, more data than previous is generated, because some source data are 60s \n",
        "test_signals, test_labels = generate_segment_data(test_ECG_signals,test_init_labels,9000)\n",
        "print('test signals dim:',test_signals.shape)\n",
        "print('test labels dim:',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Isl1albL6O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add normalization to signals\n",
        "test_signals = sklearn.preprocessing.scale(test_signals)\n",
        "print('After normalization, test signals dim:',test_signals.shape)\n",
        "print('After normalization, test labels dim:',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5cnu91kci8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resample the test ECG signal\n",
        "from wfdb import processing\n",
        "resamp_test_ECG_signals = []\n",
        "for i in range(len(test_signals)):\n",
        "  resamp_test_ECG_signal, t = wfdb.processing.resample_sig(test_signals[i],300,125)\n",
        "  resamp_test_ECG_signals.append(resamp_test_ECG_signal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L8S7Xy1kzBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Resampled ECG signal dim:', len(resamp_test_ECG_signals[0]))\n",
        "print('Resampled ECG signals len:', len(resamp_test_ECG_signals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfkUozRekVy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resize the dimension for use in CNN\n",
        "test_signals = np.expand_dims(resamp_test_ECG_signals,axis=1)\n",
        "test_signals = np.expand_dims(test_signals,axis=3)\n",
        "print('test signals dim after resize:',test_signals.shape)\n",
        "print('test labels dim after resize:',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368K5eYZR6gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check unique labels\n",
        "unique, count = np.unique(test_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in test dataset')\n",
        "print('There are', count[1], 'Afib records test dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsSsDMDSjW0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert test labels to floating point type, so that it can be compared with model output\n",
        "test_labels = test_labels.flatten()\n",
        "test_labels = test_labels.astype(float)\n",
        "type(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBe67QpCuEf",
        "colab_type": "text"
      },
      "source": [
        "##3.2 Extract, Transform and Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBWlyLWskq8C",
        "colab_type": "text"
      },
      "source": [
        "###3.2.1 Parallelize Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb-w63Qfbo6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = tf.strings.to_number(train_labels)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_signals,train_labels))\n",
        "val_labels = tf.strings.to_number(val_labels)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_signals,val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5wqFGtUkFwj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 3.2.2 Parallelize Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82EjsJdzjZF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "#dataset = dataset.map(function, num_parallel_calls = cores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSTkXW9WkMyy",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.3 Parallelize Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uv100RJLVkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(2048).repeat().batch(batch_size,drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU63IyGVDCJI",
        "colab_type": "text"
      },
      "source": [
        "#4.Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VnYDT576ZCE",
        "colab_type": "text"
      },
      "source": [
        "##4.1 Build the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZmOwuWRj1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    #1st Conv2D\n",
        "    tf.keras.layers.Conv2D(8, (1, 1), strides=(1, 1), \n",
        "                          activation='relu', input_shape=(1,3750,1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #2nd Conv2D\n",
        "    tf.keras.layers.Conv2D(16, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #3rd Conv2D\n",
        "    tf.keras.layers.Conv2D(32, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #4th Conv2D\n",
        "    tf.keras.layers.Conv2D(64, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #5th Conv2D\n",
        "    tf.keras.layers.Conv2D(16, (1, 1), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Full connection layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.LSTM(50, stateful=True, return_sequences=True),\n",
        "    #tf.keras.layers.LSTM(10, stateful=True),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwW8RHye6jBS",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Define callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EJdqB6FDrO",
        "colab_type": "text"
      },
      "source": [
        "###4.2.1 Learning rate scheduler callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7bpnzu8E59B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decay(epoch):\n",
        "  if epoch < 30:\n",
        "    return 1e-3\n",
        "  elif epoch >= 30 and epoch < 70:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLpoZJXRE_F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: schedule a learning rate incline iteration\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZUBMR-MG2mJ",
        "colab_type": "text"
      },
      "source": [
        "###4.2.2 Tensorboard callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVp0DyKdG5up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: tensorboard\n",
        "log_dir=r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\logs\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") +\"resnet_045ECG_025PPG\"\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6yI-nje0P1q",
        "colab_type": "text"
      },
      "source": [
        "###4.2.3 Create a Confusion Matrix callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ny7egL6l7iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    \"\"\"\n",
        "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\n",
        "    \"\"\"\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    \n",
        "    # Use plt.savefig to save the plot to a PNG in memory.\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    \n",
        "    # Use tf.image.decode_png to convert the PNG buffer\n",
        "    # to a TF image. Make sure you use 4 channels.\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    \n",
        "    # Use tf.expand_dims to add the batch dimension\n",
        "    image = tf.expand_dims(image,0)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJf2f1z0Hry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['NO Afib','Afib']\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, normalize=False):\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    plt.ylim(bottom=1.5,top = -0.5)\n",
        "    \n",
        "    if normalize:\n",
        "      cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 1.5\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, cm[i, j], \n",
        "               horizontalalignment=\"center\", \n",
        "               verticalalignment='center', \n",
        "               color=\"white\" if cm[i, j] > threshold else \"black\")\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idsP-pwr0q3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "    \n",
        "    # Use the model to predict the values from the test_images.\n",
        "    test_pred_raw = model.predict(test_signals)\n",
        "    \n",
        "    test_pred = np.where(test_pred_raw > 0.5, 1, 0)\n",
        "    \n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "    \n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names, normalize = True)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpfkBVciG-My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: confusion matrix\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqYofOcoHBRn",
        "colab_type": "text"
      },
      "source": [
        "###4.2.4 Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WPqDHVHE2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: checkpoint\n",
        "filepath = r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\models\\resnet-045ECG-p01-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEmb8aS60tLW",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWKdHVBBdKYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear history if necessary\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#train model\n",
        "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) ##to overwrite NCCL cross device communication as this is running in Windows\n",
        "#with strategy.scope():\n",
        "\n",
        "model = model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss=tf.keras.losses.binary_crossentropy, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "callbacks_list = [tensorboard_callback, cm_callback, checkpoint, lr_schedule]\n",
        "\n",
        "#start training\n",
        "model.fit(train_dataset,\n",
        "          epochs=200,\n",
        "          steps_per_epoch = int(len(list(train_signals))/batch_size),\n",
        "          verbose=1,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps = int(len(list(val_signals))/batch_size),\n",
        "          callbacks=callbacks_list\n",
        "          );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDBRWOlIWFb3",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Save Model for future evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjY5Zt04WPBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model.save('Deep_ECG_125Hz_Normal_Weight.h5')\n",
        "print(\"Save model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsZzsnHSmqsu",
        "colab_type": "text"
      },
      "source": [
        "#5.Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "donFYwuDXcq3",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqYK8pToXaap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model = tf.keras.models.load_model('Deep_ECG_125Hz_Normal_Weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh0Y8A7RVbQD",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8NLC_r9_OlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.006\n",
        "test_pred_raw = model.predict(test_signals)\n",
        "test_pred = np.where(test_pred_raw > threshold, 1, 0)\n",
        "# Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "figure_norm = plot_confusion_matrix(cm, class_names=class_names, normalize=True)\n",
        "figure_norm.show()\n",
        "figure = plot_confusion_matrix(cm, class_names=class_names, normalize=False)\n",
        "figure.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKTtsjpKVgMb",
        "colab_type": "text"
      },
      "source": [
        "## 5.3 F-1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcu2_YJUbHGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = sklearn.metrics.classification_report(test_labels, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvq1DoPvQYxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzgVyTxeVp5x",
        "colab_type": "text"
      },
      "source": [
        "## 5.4 AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFGzdn-5QZnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = sklearn.metrics.roc_auc_score(test_labels, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv8nmSe_Q4W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re4CuTxtQ5dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "probs = model.predict_proba(test_signals)\n",
        "preds = probs[:,]\n",
        "fpr, tpr, threshold = metrics.roc_curve(test_labels, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}