{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Afib_PPG_simple_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/jDhOtzn0tXowoWZ+h8KG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/Afib_PPG/blob/master/Afib_PPG_simple_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWP-_pXlUKmp",
        "colab_type": "text"
      },
      "source": [
        "#1.Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mOoV1yuUKlh",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains an simple PPG DNN by using labeled PPG data from Afib_Data_Clean notebook;\n",
        "The loaded data is 30s segemented PPG signals with 125Hz sampling rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfCfr60kSTDU",
        "colab_type": "text"
      },
      "source": [
        "#2.Setup Environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvqxVijHSFk2",
        "colab_type": "code",
        "outputId": "fe1a190b-b299-41d7-a2f1-5664da03252b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sklearn.metrics\n",
        "import itertools\n",
        "import io\n",
        "import pickle\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8y478FMSLVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this cell to log device placement info\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Qo9PRdSOdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "22a55c51-8b8e-4234-f473-94c908130604"
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17333853469284814064\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 6599774044\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14603473728373089246\n",
            "physical_device_desc: \"device: 0, name: Quadro RTX 4000, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
            ", name: \"/device:GPU:1\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 6599774044\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 15269238999166849712\n",
            "physical_device_desc: \"device: 1, name: Quadro RTX 4000, pci bus id: 0000:05:00.0, compute capability: 7.5\"\n",
            ", name: \"/device:GPU:2\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 6599774044\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7672319993220115788\n",
            "physical_device_desc: \"device: 2, name: Quadro RTX 4000, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
            ", name: \"/device:GPU:3\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 6599774044\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 891656843587387626\n",
            "physical_device_desc: \"device: 3, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpW2rfESO-0",
        "colab_type": "code",
        "outputId": "7ed82acc-df0e-401b-ee17-8f579148c993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oFD2ZNOoGMsP"
      },
      "source": [
        "#3.Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KpK35SW3GMsU"
      },
      "source": [
        "## 3.1 Input Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyzcW402CE7r",
        "colab_type": "text"
      },
      "source": [
        "###3.1.1 Concatenate\n",
        "Run the following code if data and label have not been concatenated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgQl-N5zqA0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenate data\n",
        "def concatenate_data(directory):\n",
        "  raw_signals_list = []\n",
        "  files_list = directory + \"filtered_PPG*.pkl\"\n",
        "  for name in glob.glob(files_list):\n",
        "    raw_signal = pickle.load(open(name,'rb'))\n",
        "    raw_signals_list.append(raw_signal)\n",
        "  raw_signals = [y for x in raw_signals_list for y in x]\n",
        "  return raw_signals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQbRUHiBK1X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load PPG signal\n",
        "raw_signals = concatenate_data('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBFjh6t_2isb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/data', \"wb\") as fp:\n",
        "  pickle.dump(raw_signals, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ujLqJDnSiKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenate label\n",
        "def concatenate_label(directory):\n",
        "  raw_labels_list = []\n",
        "  files_list = directory + \"ECG_Afib_labels*.csv\"\n",
        "  for name in glob.glob(files_list):\n",
        "    df = pd.read_csv(name,header=None)\n",
        "    labels = df.to_numpy()\n",
        "    raw_labels_list.append(labels.tolist())\n",
        "    \n",
        "  raw_labels = [y for x in raw_labels_list for y in x]\n",
        "  return raw_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruQdDT6vZVsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_labels = concatenate_label('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSNI0tT_vl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/labels', \"wb\") as fp:\n",
        "  pickle.dump(raw_labels, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zeVPo0_ZIS",
        "colab_type": "text"
      },
      "source": [
        "###3.1.2 Load data and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53We0mIum1Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/data', \"rb\") as fp:\n",
        "  raw_signals = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJxRwdweCvpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib PPG data/015ECG_015PPG_flatline/labels', \"rb\") as fp:\n",
        "  raw_labels = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKl8DpkGJiPk",
        "colab_type": "code",
        "outputId": "86a30daf-f195-4c94-9703-90134c8313e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#create the right dim for signals\n",
        "raw_signals = np.array(raw_signals)\n",
        "print('signals dim before resize',raw_signals.shape)\n",
        "raw_signals = np.expand_dims(raw_signals, axis=2)\n",
        "print('signals dim:', raw_signals.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "signals dim before resize (450701, 3750)\n",
            "signals dim: (450701, 3750, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjDHx1tyYTPR",
        "colab_type": "code",
        "outputId": "f8c10c64-99c7-4943-c352-807cd987b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "raw_labels = np.array(raw_labels)\n",
        "print('labels dim',raw_labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels dim (450701, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp2Wbr44C_f1",
        "colab_type": "text"
      },
      "source": [
        "###3.1.2 Generate train,val and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07gKGNgmBxuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ratio value is between 0 and 1\n",
        "#make sure seed is set to a same number for repeatable results\\\n",
        "#or to compare models apple to apple\n",
        "def slice_dataset(dataset,labels,train_ratio,seed = 10):  \n",
        "  DATASET_SIZE =len(list(dataset)) #only works in eager mode (e.g. TF version >= 2.0.x)\n",
        "  train_size = int(train_ratio * DATASET_SIZE)\n",
        "  val_size = DATASET_SIZE - train_size\n",
        "  \n",
        "  np.random.seed(seed=seed)\n",
        "  np.random.shuffle(dataset)\n",
        "  train_dataset = dataset[:train_size,:,:]\n",
        "  val_dataset = dataset[-val_size:,:,:]\n",
        "\n",
        "  np.random.seed(seed=seed)\n",
        "  np.random.shuffle(labels)\n",
        "  train_labels = labels[:train_size,:]\n",
        "  val_labels = labels[-val_size:,:]\n",
        "\n",
        "  return train_dataset,val_dataset,train_labels, val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWoDO-CFDJtq",
        "colab_type": "text"
      },
      "source": [
        "Generate train, val and test data and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ER6WvB2ELH",
        "colab_type": "code",
        "outputId": "2c69830b-16f9-48a5-ccb1-e30c91d462c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train_dataset, test_dataset, train_labels, test_labels  = slice_dataset(raw_signals,raw_labels,0.95)\n",
        "print(\"train_dataset dim\", train_dataset.shape)\n",
        "print(\"train_labels dim\", train_labels.shape)\n",
        "print(\"test_dataset dim\", test_dataset.shape)\n",
        "print(\"test_labels dim\", test_labels.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dataset dim (428165, 3750, 1)\n",
            "train_labels dim (428165, 1)\n",
            "test_dataset dim (22536, 3750, 1)\n",
            "test_labels dim (22536, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6sX02K7zx4j",
        "colab_type": "code",
        "outputId": "27e8370f-fdf3-4419-bf2f-27bb41439ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train_dataset, val_dataset, train_labels, val_labels  = slice_dataset(train_dataset,train_labels,0.9)\n",
        "print(\"train_dataset dim\", train_dataset.shape)\n",
        "print(\"train_labels dim\", train_labels.shape)\n",
        "print(\"val_dataset dim\", val_dataset.shape)\n",
        "print(\"val_labels dim\", val_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dataset dim (385348, 3750, 1)\n",
            "train_labels dim (385348, 1)\n",
            "val_dataset dim (42817, 3750, 1)\n",
            "val_labels dim (42817, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-RT-91ID_zl",
        "colab_type": "text"
      },
      "source": [
        "Check the distribution of Afib and No-Afib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2aa73afd-b025-4d15-fa25-1b7b30da44e1",
        "id": "ziYh6d2YGMs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#check unique labels in train dataset\n",
        "unique, count = np.unique(train_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in training dataset')\n",
        "print('There are', count[1], 'Afib records in training dataset')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 305187 No Afib records in training dataset\n",
            "There are 80161 Afib records in training dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6785268a-f259-411a-e015-2e78c58314c5",
        "id": "1uZfksv4GMs4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#check unique labels in train dataset\n",
        "unique, count = np.unique(val_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in validation dataset')\n",
        "print('There are', count[1], 'Afib records in validation dataset')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 33911 No Afib records in validation dataset\n",
            "There are 8906 Afib records in validation dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3dce9795-aaa8-4a13-d18f-f7853f4db171",
        "id": "YvJDtg4tGMs6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#check unique labels in test dataset\n",
        "unique, count = np.unique(test_labels,return_counts=True)\n",
        "print('There are', count[0], 'No Afib records in test dataset')\n",
        "print('There are', count[1], 'Afib records in test dataset')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 17856 No Afib records in test dataset\n",
            "There are 4680 Afib records in test dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4u32j5uJGMs8"
      },
      "source": [
        "## 3.2 Extract, Transform and Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bG4_EtxRGMs8"
      },
      "source": [
        "###3.2.1 Parallelize Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0Mo73K8GMs9",
        "colab": {}
      },
      "source": [
        "#use interleave if more than one file are used\n",
        "train = tf.data.Dataset.from_tensor_slices((train_dataset,train_labels)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaQyR9mhGMs_",
        "colab": {}
      },
      "source": [
        "validation = tf.data.Dataset.from_tensor_slices((val_dataset,val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ss2nwlA3GMtB"
      },
      "source": [
        "### 3.2.2 Parallelize Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "988c8f16-7016-45c0-a876-1b741a94dd64",
        "id": "wt9paii8GMtB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#don't need to run this cell, just as a placeholder\n",
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "#dataset = dataset.map(function, num_parallel_calls = cores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0PxkcHUtGMtD"
      },
      "source": [
        "### 3.2.3 Parallelize Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eNX0PYsGMtE",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_dataset = train.cache()\n",
        "train_dataset = train_dataset.shuffle(len(list(train))).repeat().batch(batch_size,drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = validation.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiF9-uDTI-h",
        "colab_type": "text"
      },
      "source": [
        "#4.Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeF1mUEJTN60",
        "colab_type": "text"
      },
      "source": [
        "##4.1 Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwPKkjtNlpUK",
        "colab_type": "code",
        "outputId": "8f425e6d-5d44-4a03-a2b2-810289968dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "source": [
        "#create a model\n",
        "model = tf.keras.Sequential([\n",
        "    #1st Conv1D\n",
        "    tf.keras.layers.Conv1D(8, 1, strides=1, \n",
        "                          activation='relu', input_shape=(3750,1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #2nd Conv1D\n",
        "    tf.keras.layers.Conv1D(16, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #3rd Conv1D\n",
        "    tf.keras.layers.Conv1D(32, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #4th Conv1D\n",
        "    tf.keras.layers.Conv1D(64, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #5th Conv1D\n",
        "    tf.keras.layers.Conv1D(16, 1, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Full connection layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.LSTM(50, stateful=True, return_sequences=True),\n",
        "    #tf.keras.layers.LSTM(10, stateful=True),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 3750, 8)           16        \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 3750, 8)           32        \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 1875, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1875, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1873, 16)          400       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1873, 16)          64        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 936, 16)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 936, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 934, 32)           1568      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 934, 32)           128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 467, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 467, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 465, 64)           6208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 465, 64)           256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 232, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 232, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 232, 16)           1040      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 232, 16)           64        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3712)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                237632    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 247,729\n",
            "Trainable params: 247,329\n",
            "Non-trainable params: 400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV4AOP5AXh5P",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Define callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1LxToVXqBO",
        "colab_type": "text"
      },
      "source": [
        "###4.2.1 Learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqkfWOvWXlfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decay(epoch):\n",
        "  if epoch < 10:\n",
        "    return 1e-3\n",
        "  elif epoch >= 10 and epoch < 30:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyV2EoQtXtV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: schedule a learning rate incline iteration\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8quc5CXwa5",
        "colab_type": "text"
      },
      "source": [
        "###4.2.2 Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7h_p1YnXz1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: tensorboard\n",
        "log_dir=r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\\logs\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") +\"simpleCNN_015ECG_015PPG\"\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDmi_YP3X2TM",
        "colab_type": "text"
      },
      "source": [
        "###4.2.3 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L2FJoWOTWJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    \"\"\"\n",
        "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\n",
        "    \"\"\"\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    \n",
        "    # Use plt.savefig to save the plot to a PNG in memory.\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    \n",
        "    # Use tf.image.decode_png to convert the PNG buffer\n",
        "    # to a TF image. Make sure you use 4 channels.\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    \n",
        "    # Use tf.expand_dims to add the batch dimension\n",
        "    image = tf.expand_dims(image,0)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81b0Rp0TX81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['NO Afib','Afib']\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, normalize=False):\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    plt.ylim(bottom=1.5,top = -0.5)\n",
        "    \n",
        "    if normalize:\n",
        "      cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 1.5\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, cm[i, j], \n",
        "               horizontalalignment=\"center\", \n",
        "               verticalalignment='center', \n",
        "               color=\"white\" if cm[i, j] > threshold else \"black\")\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hAk0QPETZ95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "    \n",
        "    # Use the model to predict the values from the test_images.\n",
        "    test_pred_raw = model.predict(test_dataset)\n",
        "    \n",
        "    test_pred = np.where(test_pred_raw > 0.5, 1, 0)\n",
        "    \n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "    \n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names, normalize = True)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmn0QY63X9i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: confusion matrix\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcdMgfv1YClx",
        "colab_type": "text"
      },
      "source": [
        "###4.2.4 Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSqNrDZ_YKFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: checkpoint\n",
        "filepath = r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\models\\sCNN-015ECG-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ril_S4TVJS",
        "colab_type": "text"
      },
      "source": [
        "##4.3 Train the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYor7DsTcXT",
        "colab_type": "text"
      },
      "source": [
        "### 4.3.1 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eqeVT1uTeOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear history if necessary\n",
        "tf.keras.backend.clear_session()\n",
        "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) ##to overwrite NCCL cross device communication as this is running in Windows\n",
        "#with strategy.scope():\n",
        "\n",
        "model = model\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss=tf.keras.losses.binary_crossentropy, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks_list = [tensorboard_callback, cm_callback, checkpoint, lr_schedule]\n",
        "\n",
        "#start training\n",
        "model.fit(train_dataset,\n",
        "          epochs=100,\n",
        "          steps_per_epoch = len(list(train))/batch_size,\n",
        "          verbose=1,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps = len(list(validation))/batch_size,\n",
        "          callbacks=callbacks_list\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUv7BhOTiua",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Save Model for future evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricCF8i5Tnoz",
        "colab_type": "code",
        "outputId": "d44f2063-2e78-4a59-caf8-9a582c87ce2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model.save('Deep_PPG_CNN_041120.h5')\n",
        "print(\"Save model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfnasVq2Tqjg",
        "colab_type": "text"
      },
      "source": [
        "# 5.Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a8QzHAVT1bz",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZyzAHekTsy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\models\\ResNet 05-05-2020\")\n",
        "model = tf.keras.models.load_model('resnet-015E-015P-14-0.3596.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aMp1YpLTw7C",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJD3CxiTTuse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.5\n",
        "test_pred_raw = model.predict(test_dataset)\n",
        "test_pred = np.where(test_pred_raw > threshold, 1, 0)\n",
        "# Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "figure_norm = plot_confusion_matrix(cm, class_names=class_names, normalize=True)\n",
        "figure_norm.show()\n",
        "figure = plot_confusion_matrix(cm, class_names=class_names, normalize=False)\n",
        "figure.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yq00AMzT5n6",
        "colab_type": "text"
      },
      "source": [
        "## 5.3 F-1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6_xv9F1T7xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = sklearn.metrics.classification_report(test_labels, test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnnZD1InT9_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6DNehETT_dL",
        "colab_type": "text"
      },
      "source": [
        "## 5.4 AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cextNotUBHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = sklearn.metrics.roc_auc_score(test_labels, test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cNSvIDgUC9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSc3QXS2UEJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "probs = model.predict(test_dataset)\n",
        "preds = probs[:,]\n",
        "fpr, tpr, threshold = metrics.roc_curve(test_labels, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}