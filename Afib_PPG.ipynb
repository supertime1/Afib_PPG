{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Afib_PPG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsjxRqMeHYhjInnDGTiOLk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/Afib_PPG/blob/master/Afib_PPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWP-_pXlUKmp",
        "colab_type": "text"
      },
      "source": [
        "#1.Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mOoV1yuUKlh",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains an PPG DNN by using labeled PPG data from Afib_Data_Clean notebook;\n",
        "The loaded data is 30s segemented PPG signals with 125Hz sampling rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfCfr60kSTDU",
        "colab_type": "text"
      },
      "source": [
        "#2.Setup Environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvqxVijHSFk2",
        "colab_type": "code",
        "outputId": "b589792b-7923-491e-939e-4f80be3cb4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sklearn.metrics\n",
        "import itertools\n",
        "import io\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8y478FMSLVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this cell if multiple GPUs are used\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Qo9PRdSOdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpW2rfESO-0",
        "colab_type": "code",
        "outputId": "af2626d1-a6fc-4ba0-c31d-b6d1e525ec9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_wxDhglSU7P",
        "colab_type": "text"
      },
      "source": [
        "#3.Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsPZhklkSiHI",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQbRUHiBK1X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load signal\n",
        "with open('D:WFDB//matched/seg_PPG_signals_p09.pkl', \"rb\") as fp:\n",
        "  raw_signals = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKl8DpkGJiPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the right dim\n",
        "print('signals dim:', raw_signals.shape)\n",
        "signals = np.expand_dims(raw_signals, axis=1)\n",
        "signals = np.expand_dims(signals,axis=3)\n",
        "print('signals dim after resize', signals.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4sclRClSYcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load label\n",
        "df = pd.read_csv('D:WFDB//matched/ECG_Afib_labels_p09.csv',sep=',', header=None)\n",
        "labels\n",
        "print('labels dim',lables.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xprd3SoCSl71",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Extract, Transform and Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXIJQPgJSz4Y",
        "colab_type": "text"
      },
      "source": [
        "###3.2.1 Parallelize Extraction (how?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA6BLiLnSQci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = tf.strings.to_number(labels) \n",
        "dataset = tf.data.Dataset.from_tensor_slices((signals,labels))\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07gKGNgmBxuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###ratio value is between 0 and 1\n",
        "def slice_dataset(dataset,train_ratio):\n",
        "  DATASET_SIZE =len(list(dataset)) #only works in eager mode (e.g. TF version >= 2.0.x)\n",
        "  dataset = dataset.shuffle(DATASET_SIZE)\n",
        "\n",
        "  train_size = int(train_ratio * DATASET_SIZE)\n",
        "  val_size = int((1-train_ratio) * DATASET_SIZE)\n",
        "\n",
        "  train_dataset = dataset.take(train_size)\n",
        "  val_dataset = dataset.skip(train_size)\n",
        "\n",
        "  return train_dataset,val_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3w1C-GJk2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create training, validation and test dataset\n",
        "train_dataset, test = slice_dataset(dataset, 0.9)\n",
        "train, validation = slice_dataset(train_dataset,0.8)\n",
        "print('size of training data:',len(list(train)))\n",
        "print('size of validation data:',len(list(validation)))\n",
        "print('size of test data:',len(list(test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fResed9S2cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print and visualize the data\n",
        "for signal, label in tfds.as_numpy(dataset.take(2)):\n",
        "  print(signal.shape, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcGMR4eeS35c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optional: data preprocessing use dataset.map(function)\n",
        "#possible functions:\n",
        "#1.Spectrogram\n",
        "#2.Hample filter\n",
        "#3.Flat line and peak removal\n",
        "#4.Normalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn_mIRbwS6tQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.2 Parallelize Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf_TMonOS9Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "#dataset = dataset.map(function, num_parallel_calls = cores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq6jK1foTFCU",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.3 Parallelize Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2aSxbkTF96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(1024).repeat().batch(batch_size,drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiF9-uDTI-h",
        "colab_type": "text"
      },
      "source": [
        "#4. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeF1mUEJTN60",
        "colab_type": "text"
      },
      "source": [
        "##4.1 Build the model and find the optimal learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGbK_IbTLMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear history if necessary\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#train model\n",
        "learning_rate = 0.0001\n",
        "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) ##to overwrite NCCL cross device communication as this is running in Windows\n",
        "#with strategy.scope():\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    #1st Conv2D\n",
        "    tf.keras.layers.Conv2D(8, (1, 1), strides=(1, 1), \n",
        "                          activation='relu', input_shape=(1,1,9000,1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #2nd Conv2D\n",
        "    tf.keras.layers.Conv2D(16, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #3rd Conv2D\n",
        "    tf.keras.layers.Conv2D(32, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #4th Conv2D\n",
        "    tf.keras.layers.Conv2D(64, (1, 3), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #5th Conv2D\n",
        "    tf.keras.layers.Conv2D(16, (1, 1), strides=(1, 1),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Full connection layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.LSTM(50, stateful=True, return_sequences=True),\n",
        "    #tf.keras.layers.LSTM(10, stateful=True),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n",
        "              loss=tf.keras.losses.binary_crossentropy, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#callback: schedule a learning rate incline iteration\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-4 * 10**(epoch / 20))\n",
        "\n",
        "#callback: tensorboard\n",
        "log_dir=\"logs\\\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, update_freq='batch', histogram_freq=1)\n",
        "\n",
        "#start training\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=10,\n",
        "                    steps_per_epoch = len(list(dataset))*0.8/batch_size,\n",
        "                    verbose=0,\n",
        "                    validation_data=val_dataset,\n",
        "                    validation_steps = len(list(dataset))*0.1/batch_size,\n",
        "                    callbacks=[lr_schedule,tensorboard_callback]\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXVnKYMLTQ4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize learning rate vs epoches\n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-4, 1e-2,0,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ril_S4TVJS",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Train the model with the optimal learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L2FJoWOTWJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    \"\"\"\n",
        "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\n",
        "    \"\"\"\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    \n",
        "    # EXERCISE: Use plt.savefig to save the plot to a PNG in memory.\n",
        "    # YOUR CODE HERE\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    \n",
        "    # EXERCISE: Use tf.image.decode_png to convert the PNG buffer\n",
        "    # to a TF image. Make sure you use 4 channels.\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    \n",
        "    # EXERCISE: Use tf.expand_dims to add the batch dimension\n",
        "    image = tf.expand_dims(image,0)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81b0Rp0TX81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://axbihaqixpqbrrxincyxja.coursera-apps.org/notebooks/week3/TF_Serving_Week_3_Exercise_Question.ipynb\n",
        "\n",
        "class_names = ['NO Afib','Afib']\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, normalize=False):\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    plt.ylim(bottom=1.5,top = -0.5)\n",
        "    \n",
        "    if normalize:\n",
        "      cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 1.5\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, cm[i, j], \n",
        "               horizontalalignment=\"center\", \n",
        "               verticalalignment='center', \n",
        "               color=\"white\" if cm[i, j] > threshold else \"black\")\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hAk0QPETZ95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "    \n",
        "    # EXERCISE: Use the model to predict the values from the test_images.\n",
        "    test_pred_raw = model.predict(test_signals)\n",
        "    \n",
        "    test_pred = np.where(test_pred_raw > 0.5, 1, 0)\n",
        "    \n",
        "    # EXERCISE: Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "    \n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names, normalize = True)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYor7DsTcXT",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.2 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eqeVT1uTeOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#clear history if necessary\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#train model\n",
        "learning_rate = 0.003 #choose the optimal learning rate\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) ##to overwrite NCCL cross device communication as this is running in Windows\n",
        "with strategy.scope():\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      #1st Conv2D\n",
        "      tf.keras.layers.Conv2D(8, (1, 1), strides=(1, 1), \n",
        "                            activation='relu', input_shape=(1,9000,1)),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      #2nd Conv2D\n",
        "      tf.keras.layers.Conv2D(16, (1, 3), strides=(1, 1),\n",
        "                            activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      #3rd Conv2D\n",
        "      tf.keras.layers.Conv2D(32, (1, 3), strides=(1, 1),\n",
        "                            activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      #4th Conv2D\n",
        "      tf.keras.layers.Conv2D(64, (1, 3), strides=(1, 1),\n",
        "                            activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(1, 2),strides=(1, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      #5th Conv2D\n",
        "      tf.keras.layers.Conv2D(16, (1, 1), strides=(1, 1),\n",
        "                            activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      #Full connection layer\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n",
        "              loss=tf.keras.losses.binary_crossentropy, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#callback: tensorboard\n",
        "log_dir=\"logs\\\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
        "\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, update_freq='batch', profile_batch=1, histogram_freq=1)\n",
        "\n",
        "#start training\n",
        "model.fit(train_dataset,\n",
        "          epochs=200,\n",
        "          steps_per_epoch = len(list(dataset))*0.8/batch_size,\n",
        "          verbose=0,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps = len(list(dataset))*0.1/batch_size,\n",
        "          callbacks=[tensorboard_callback, cm_callback]\n",
        "          );"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f4i7w_DThVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUv7BhOTiua",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Save Model for future evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw29XiWcTlxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricCF8i5Tnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model.save('Deep_ECG.h5')\n",
        "print(\"Save model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfnasVq2Tqjg",
        "colab_type": "text"
      },
      "source": [
        "# 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a8QzHAVT1bz",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZyzAHekTsy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model = tf.keras.models.load_model('Deep_ECG.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aMp1YpLTw7C",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJD3CxiTTuse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.2\n",
        "test_pred_raw = model.predict(test_signals)\n",
        "test_pred = np.where(test_pred_raw > threshold, 1, 0)\n",
        "# EXERCISE: Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "figure_norm = plot_confusion_matrix(cm, class_names=class_names, normalize=True)\n",
        "figure_norm.show()\n",
        "figure = plot_confusion_matrix(cm, class_names=class_names, normalize=False)\n",
        "figure.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yq00AMzT5n6",
        "colab_type": "text"
      },
      "source": [
        "## 5.3 F-1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6_xv9F1T7xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = sklearn.metrics.classification_report(test_labels, test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnnZD1InT9_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6DNehETT_dL",
        "colab_type": "text"
      },
      "source": [
        "## 5.4 AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cextNotUBHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = sklearn.metrics.roc_auc_score(test_labels, test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cNSvIDgUC9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSc3QXS2UEJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "probs = model.predict_proba(test_signals)\n",
        "preds = probs[:,]\n",
        "fpr, tpr, threshold = metrics.roc_curve(test_labels, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}