{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD_-cpvPGQyK"
      },
      "source": [
        "#Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0X7DBegvBxs"
      },
      "source": [
        "import sys\n",
        "sys.path.append('C:/Users/57lzhang.US04WW4008/PycharmProjects/AF')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtJCBohYlUoG",
        "outputId": "62e953ad-a15c-40f8-de4d-9b5908c0fd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from util import util, model_util\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHweWIpxGZfd"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RvBpqmqBqj",
        "outputId": "257c6621-bf9d-45b4-d37e-4bbfb7a11cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# load training data\n",
        "train_data_file_path = \"C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib ECG data/training2017/\"\n",
        "raw_signals, raw_labels = util.data_mining(train_data_file_path)\n",
        "signals, labels = util.generate_seg_data(raw_signals, raw_labels, seg_len=9000)\n",
        "signals, labels = util.preprocessing(signals, labels, timedistributed=True)\n",
        "train_signals, train_labels, val_signals, val_labels = util.split_shuffle_dataset(signals, labels, 0.9)\n",
        "print('train_signal shape:', train_signals.shape)\n",
        "print('train_label shape:', train_labels.shape)\n",
        "print(\"\\nIn training data:\") \n",
        "util.count_labels(train_labels)\n",
        "print(\"\\nIn validation data:\")\n",
        "util.count_labels(val_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_signal shape: (7425, 3, 1250, 1)\n",
            "train_label shape: (7425, 3)\n",
            "\n",
            "In training data:\n",
            "There are 4430 NSR labels\n",
            "There are 653 AF labels\n",
            "There are 2342 Other Arrhythmia labels\n",
            "\n",
            "In validation data:\n",
            "There are 502 NSR labels\n",
            "There are 62 AF labels\n",
            "There are 261 Other Arrhythmia labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(502, 62, 261)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo6D2eX3qFZu",
        "outputId": "2dad6be1-589f-42f1-eea4-27bf3b8d86f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# load testing data\n",
        "test_data_file_path = \"C:/Users/57lzhang.US04WW4008/Desktop/Afib/Afib data/Afib ECG data/validation/\"\n",
        "test_raw_signals, test_raw_labels = util.data_mining(test_data_file_path)\n",
        "test_signals, test_labels = util.generate_seg_data(test_raw_signals, test_raw_labels, seg_len=9000)\n",
        "test_signals, test_labels = util.preprocessing(test_signals, test_labels, timedistributed=True)\n",
        "print('test_signal shape:', test_signals.shape)\n",
        "print('test_label shape:', test_labels.shape)\n",
        "print(\"\\nIn test data:\") \n",
        "util.count_labels(test_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_signal shape: (276, 3, 1250, 1)\n",
            "test_label shape: (276, 3)\n",
            "\n",
            "In test data:\n",
            "There are 150 NSR labels\n",
            "There are 47 AF labels\n",
            "There are 79 Other Arrhythmia labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 47, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckuxUrs1GeC7"
      },
      "source": [
        "#TF Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdOBgPBPqI39"
      },
      "source": [
        "# tensorflow pipeline\n",
        "## extraction\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_signals, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_signals, val_labels))\n",
        "## loading\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(2048).repeat().batch(batch_size, drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvv8pVHmGsFs"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aI3zST7wmZy"
      },
      "source": [
        "#cnn + lstm model\n",
        "model = model_util.CNN_LSTM((3,1250,1), classes=3)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzvxI017CUxW"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gtz0mpPGMdI"
      },
      "source": [
        "#Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1fo9D09kM5n"
      },
      "source": [
        "# callbacks\n",
        "log_dir = r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\logs\\fit\\\\\" + \\\n",
        "          datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"resnet\"\n",
        "\n",
        "## confusion matrix callback\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "    # Use the model to predict the values from the test_images.\n",
        "    \n",
        "    test_pred_raw = model.predict(val_signals)\n",
        "\n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "    test_labels = np.argmax(val_labels, axis=1)\n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "\n",
        "    figure = model_util.plot_confusion_matrix(cm, class_names=class_names, normalize=True)\n",
        "    cm_image = model_util.plot_to_image(figure)\n",
        "\n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "class_names = ['NO Afib','Afib','Others']\n",
        "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
        "\n",
        "## tensorboard callback\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "## checkpoint callback\n",
        "filepath = r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\models\\resnet-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "## learning rate decay callback\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(model_util.decay)\n",
        "\n",
        "callbacks_list = [tensorboard_callback, cm_callback, checkpoint, lr_schedule]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I8W1jtdGIWv"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VS1G04J3i5G"
      },
      "source": [
        "#model training\n",
        "CLASS_WEIGHTS = util.class_weights(train_labels)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=200,\n",
        "          steps_per_epoch=len(list(train_signals))//batch_size,\n",
        "          verbose=1,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=len(list(val_signals))//batch_size,\n",
        "          callbacks=callbacks_list,\n",
        "          class_weight=CLASS_WEIGHTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzCsuNPU5-e-"
      },
      "source": [
        "#Training with Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xynJkWZep4_7"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Input, Add, Activation, \\\n",
        "    MaxPooling1D, Dropout, Flatten, TimeDistributed, Bidirectional, Dense, LSTM, ZeroPadding1D, \\\n",
        "    AveragePooling1D, Conv1DTranspose, GlobalMaxPooling1D, Concatenate, Permute, Dot, Multiply, RepeatVector, \\\n",
        "    Lambda, Average"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGotIQaT590i",
        "outputId": "bba0b0e2-a067-4b04-95cd-1077716cd1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import os\n",
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib data\\models\")\n",
        "ecg_encoder = tf.keras.models.load_model('ECG_Encoder.h5')\n",
        "conv_encoder_clone = tf.keras.models.clone_model(ecg_encoder)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBl167_mqCsB"
      },
      "source": [
        "def encoder_lstm(input_shape=(3,1250,1), classes=3):\n",
        "  X_input = Input(shape=input_shape)\n",
        "  X = TimeDistributed(conv_encoder_clone)(X_input)\n",
        "  X = Bidirectional(LSTM(32, return_sequences=True))(X)\n",
        "  X = Bidirectional(LSTM(16))\n",
        "  X = Dense(classes, activations='softmax')(X)\n",
        "\n",
        "  model = Model(inputs=[X_input], outputs=X)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkQ3Ma_orkIh",
        "outputId": "29d47ecd-3a73-438e-d768-840d9b43aa7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        }
      },
      "source": [
        "encoder_lstm = encoder_lstm(input_shape=(3,1250,1), classes=3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-80dae4555360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-12-126532098f87>\u001b[0m in \u001b[0;36mencoder_lstm\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mX_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_encoder_clone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 926\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1090\u001b[0m       \u001b[1;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m       \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    178\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 3, 1250, 16]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aht3FXHloLyj"
      },
      "source": [
        "pretrained_clf = keras.models.Sequential([\n",
        "    conv_encoder_clone,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(20, activation=\"selu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Uimoh9pR1Q"
      },
      "source": [
        "conv_encoder_clone.trainable = False\n",
        "pretrained_clf.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=keras.optimizers.SGD(lr=0.02),\n",
        "                       metrics=[\"accuracy\"])\n",
        "history = pretrained_clf.fit(X_train_small, y_train_small, epochs=30,\n",
        "                             validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}